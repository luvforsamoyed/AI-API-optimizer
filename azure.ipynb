{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe to json format\n",
    "def df_to_json(df):\n",
    "    lists = []\n",
    "    for idx, row in data_csv.iterrows():\n",
    "        lists.append({\"timestamp\": row.timestamp, \"value\": row.value})\n",
    "    df = {'granularity': 'minutely', 'series': lists}\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request(endpoint, url, subscription_key, request_data):\n",
    "    headers = {'Content-Type': 'application/json', 'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "    response = requests.post(endpoint+url, data=json.dumps(request_data), headers=headers)\n",
    "    return json.loads(response.content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Case 1. if you try to make inference on batch size dataset\n",
    "def detect_batch(request_data):\n",
    "    print(\"Detecting anomalies as a batch\")\n",
    "    result = send_request(endpoint, batch_detection_url, subscription_key, request_data)\n",
    "    print(json.dumps(result, indent=4))\n",
    "\n",
    "    if result.get('code') != None:\n",
    "        print(\"Detection failed. ErrorCode:{}, ErrorMessage:{}\".format(result['code'], result['message']))\n",
    "    else:\n",
    "        # Find and display the positions of anomalies in the data set\n",
    "        anomalies = result[\"isAnomaly\"]\n",
    "        print(\"Anomalies detected in the following data positions:\")\n",
    "        for x in range(len(anomalies)):\n",
    "            if anomalies[x] == True:\n",
    "                print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Case 2. if you try to make inference on a latest datapoint\n",
    "def detect_latest(request_data):\n",
    "    print(\"Determining if latest data point is an anomaly\")\n",
    "    # send the request, and print the JSON result\n",
    "    result = send_request(endpoint, latest_point_detection_url, subscription_key, request_data)\n",
    "    print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_detection_url = \"/anomalydetector/v1.0/timeseries/entire/detect\"\n",
    "latest_point_detection_url = \"/anomalydetector/v1.0/timeseries/last/detect\"\n",
    "\n",
    "endpoint = \"https://westus2.api.cognitive.microsoft.com/\"\n",
    "subscription_key = \"039b14e520f64e5b9907af6ac58edff2\"\n",
    "\n",
    "###if you have json dataset file\n",
    "data_location = \"***Write down your json file path***\"\n",
    "file_handler = open(data_location)\n",
    "json_data = json.load(file_handler)\n",
    "\n",
    "###if you have csv datset file: uncomment below comments\n",
    "###sample csv dataset\n",
    "# csv_location = \"https://raw.githubusercontent.com/numenta/NAB/master/data/realKnownCause/ec2_request_latency_system_failure.csv\"\n",
    "# data_csv = pd.read_csv(csv_location)\n",
    "# data_csv = data_csv.drop_duplicates(subset = 'timestamp', keep = 'first')\n",
    "# json_data = df_to_json(data_csv)\n",
    "\n",
    "#Case 1. if you try to make inference on batch size dataset\n",
    "detect_batch(json_data)\n",
    "#Case 2. if you try to make inference on a latest datapoint\n",
    "detect_latest(json_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
